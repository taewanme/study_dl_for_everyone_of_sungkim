{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4장 단일 계층 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 심층연구 레퍼런스\n",
    "  - http://neuralnetworksanddeeplearning.com\n",
    "  - ![](../images/04/neuralnetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 MNIST 데이터셋"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST\n",
    "  - 데이터 구성\n",
    "    - data for training\n",
    "      - 55000\n",
    "    - data for testing\n",
    "      - 10000\n",
    "  - 다운로드\n",
    "    - http://yann.lecun.com/exdb/mnist/\n",
    "    - ![](../images/04/mnist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MNIST 데이터 소개\n",
    "  - 20 X 20 픽셀\n",
    "  - Normalization이 됨\n",
    "  - 정규화 알고리즘에 Anti-Aliasing 처리 됨\n",
    "    - 가장 낮은 해상도로 전체 이미지 해상도 감소\n",
    "  - 이미지는 28X28 중심에 위치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 로딩\n",
    "  - tensorflow.examples.tutorials.mnist\n",
    "    - input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(mnist.train.images))\n",
    "print(len(mnist.test.images))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/04/mnist_data.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 28X28\n",
    "- 784 차원의 백터\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets('./MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mnist.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(784)])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mnist.train.images[0]\n",
    "tensor = tf.convert_to_tensor(data) # array를 tensor로 변환\n",
    "tensor.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = mnist.train.images\n",
    "train_tensor = tf.convert_to_tensor(train_images) # 2차원 배열을 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(55000), Dimension(784)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 인공뉴런"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ z = b + \\sum{x_iW_i} \\\\\n",
    "y = \\begin{cases}\n",
    "      0, & \\text{if}\\ z\\ge 0 \\\\\n",
    "      1, & \\text{if}\\ z<0\n",
    "    \\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ z = b + \\sum{x_iW_i} \\\\\n",
    "y = \\frac{1}{1+e^{-z}}   \\\\ sigmoid\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 예제: 소프트맥스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/04/softmax1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 클래스 소속 근거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ evidence_i = \\sum_{j}{W_{i,j}*x_i} $$\n",
    "$$ evidence_i = \\sum_{j}{W_{i,j} x_j} + bi $$\n",
    "\n",
    "- 결과: 특정 클래스로 소속될 수치가 계산됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 클래스 소속 확률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결과 처리의 효율성을 높이기 위해서 결과에 대한 가공\n",
    "  - 전체 합은 1\n",
    "  - 소속될 확률로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$y = softmax(evidence) \\\\\n",
    "softmax(x)_i = \\frac{exp(x_i)}{\\sum_j exp(x_j)} = \\frac{e^{x_i}}{\\sum{e^{xj}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../images/04/softmax2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- softmax는 지수함수를 사용하여 가중치의 오류를 증폭시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 텐서플로우 프로그래밍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pythoh\n",
    "W = tf.Variable(tf.zeros([784, 10])\n",
    "b = tf.Variable(tf.zeros([10])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 입력 포인트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "hypothesis = tf.nn.softmax(tf.matmul(x, W)+b)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "cross_entropy = -tf.reduce_sum(y*tf.log(hypothesis))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cross_enrtropy)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수 초기화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "sess.run(tf.initialize_all_variables())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```python\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "print(sess.run(accuracy, \n",
    "    feed_dict={\n",
    "        x:mnist.test.images, \n",
    "        y:mnist.test.labels\n",
    "    })\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"./MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W)+b)\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(y_*tf.log(y))\n",
    "train = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.43\n",
      "final:  0.95\n",
      "Tensor(\"Shape:0\", shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    correct_predict = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    for step in range(1000):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "        sess.run(train, feed_dict={x:batch_xs, y_:batch_ys})\n",
    "        \n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "        if step % 1000 == 0:\n",
    "            print(step, sess.run(accuracy, feed_dict={x:batch_xs, y_:batch_ys}))\n",
    "\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n",
    "    print(\"final: \", sess.run(accuracy, feed_dict={x:batch_xs, y_:batch_ys}))\n",
    "    weight = sess.run(W)\n",
    "    print (tf.shape(weight))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## last update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-19 04:37:01.411424\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
