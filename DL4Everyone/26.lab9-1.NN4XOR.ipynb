{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set for XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|$x_1$|$x_2$|y|\n",
    "|---|---|---|\n",
    "|0|0|0|\n",
    "|0|1|1|\n",
    "|1|0|1|\n",
    "|1|1|0|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xy = np.loadtxt('./data/xor.txt', delimiter=',', dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0],\n",
       "       [0, 1, 1],\n",
       "       [1, 0, 1],\n",
       "       [1, 1, 0]], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_data = xy[:,:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 2], name='x_placeholder')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y_placeholder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2,2], -1.0, 1.0), name='weight1')\n",
    "W2 = tf.Variable(tf.random_normal([2,1], -1.0, 1.0), name='wegiht2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- W1은 두개의 입력이 들어와서 2개의 출력이 발생\n",
    "- W2는 2개의 입력이 들어와서 1개의 출력이 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b1 = tf.Variable(tf.zeros([2]), name='bias1')\n",
    "b2 = tf.Variable(tf.zeros([1]), name='bias2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bias는 Weight의 출력 값에 맞춤\n",
    "  - W1은 출력이 2개: bias = [2]\n",
    "  - W2는 출력이 1개: bass = [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $K(x) = sigmoid(XW_1+B)$\n",
    "- $\\hat{Y} = H(X) = sigmoid(K(X)W_2+b)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L1 = tf.sigmoid(tf.matmul(X, W1)+b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L1, W2)+b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/26/nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis>0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.783793\n",
      "10000 0.569126\n",
      "20000 0.517302\n",
      "30000 0.500263\n",
      "40000 0.459569\n",
      "50000 0.295395\n",
      "60000 0.107061\n",
      "70000 0.0557931\n",
      "80000 0.0366576\n",
      "90000 0.02705\n",
      "100000 0.0213454\n",
      "\n",
      "Hypothesis:  [[ 0.01516356]\n",
      " [ 0.98118377]\n",
      " [ 0.98103607]\n",
      " [ 0.03145494]] \n",
      "Correct:  [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(100001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 10000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                      X: x_data, Y: y_data}))\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                           feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis: \", h, \"\\nCorrect: \", c, \"\\nAccuracy: \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 코드 (완성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x_placeholder')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y_placeholder')\n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2], -1.0, 1.0), name='weight1')\n",
    "b1 = tf.Variable(tf.zeros([2]), name='bias1')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1], -1.0, 1.0), name='weight1')\n",
    "b2 = tf.Variable(tf.zeros([1]), name='bias2')\n",
    "\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "L1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L1, W2)+b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.783793\n",
      "10000 0.569126\n",
      "20000 0.517302\n",
      "30000 0.500263\n",
      "40000 0.459569\n",
      "50000 0.295395\n",
      "60000 0.107061\n",
      "70000 0.0557931\n",
      "80000 0.0366576\n",
      "90000 0.02705\n",
      "100000 0.0213454\n",
      "\n",
      "Hypothesis:\n",
      "  [[ 0.01516356]\n",
      " [ 0.98118377]\n",
      " [ 0.98103607]\n",
      " [ 0.03145494]] \n",
      "Correct:\n",
      "  [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      "Accuracy:\n",
      "  1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(100001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 10000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}))\n",
    "\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis:\\n \", h, \"\\nCorrect:\\n \", c, \"\\nAccuracy:\\n \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 입력이 2개 출력은 10개인 weight와 bias정리\n",
    "- 입력이 10개이고 출력이 1개\n",
    "- Layer 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "W1 = tf.Variable(tf.random_uniform([2, 10],-1.0, 1.0), name='weight1')\n",
    "W2 = tf.Variable(tf.random_uniform([2, 1],-1.0, 1.0), name='weight2')\n",
    "B1 = tf.Variable(tf.zeros([10]),  name='bias1')\n",
    "B2 = tf.Variable(tf.zeros([1])), name='bias2')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NN 디자인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2개를 받아 5개를 출력\n",
    "- 5개를 받아 4개를 출력\n",
    "- 4개를 받아 1개를 출력\n",
    "- network은 Logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W1 = tf.Variable(tf.random_uniform([2, 5], -0.1, 1.0), name='w1')\n",
    "W2 = tf.Variable(tf.random_uniform([5, 4], -0.1, 1.0), name='w2')\n",
    "W3 = tf.Variable(tf.random_uniform([4, 1], -0.1, 1.0), name='w3')\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([5]), name='b1')\n",
    "b2 = tf.Variable(tf.zeros([4]), name='b2')\n",
    "b3 = tf.Variable(tf.zeros([1]), name='b3')\n",
    "\n",
    "L2 = tf.sigmoid(tf.matmul(X, W1)+b1)\n",
    "L3 = tf.sigmoid(tf.matmul(L2, W2)+b2)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L3, W3)+b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동일한 문제에 대하여 네트워크 구조가 갖은 변호"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x_placeholder')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y_placeholder')\n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 2], -1.0, 1.0), name='weight1')\n",
    "b1 = tf.Variable(tf.zeros([2]), name='bias1')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1], -1.0, 1.0), name='weight1')\n",
    "b2 = tf.Variable(tf.zeros([1]), name='bias2')\n",
    "\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "L1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L1, W2)+b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.819412\n",
      "10000 0.574658\n",
      "20000 0.525751\n",
      "30000 0.507222\n",
      "40000 0.498339\n",
      "50000 0.493295\n",
      "60000 0.490096\n",
      "70000 0.487908\n",
      "80000 0.486326\n",
      "90000 0.485136\n",
      "100000 0.48421\n",
      "\n",
      "Hypothesis:\n",
      "  [[ 0.01054119]\n",
      " [ 0.66128701]\n",
      " [ 0.66131794]\n",
      " [ 0.66684729]] \n",
      "Correct:\n",
      "  [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]] \n",
      "Accuracy:\n",
      "  0.75\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(100001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 10000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}))\n",
    "\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis:\\n \", h, \"\\nCorrect:\\n \", c, \"\\nAccuracy:\\n \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "learning_rate = 0.01\n",
    "\n",
    "\n",
    "x_data = [[0, 0],\n",
    "          [0, 1],\n",
    "          [1, 0],\n",
    "          [1, 1]]\n",
    "y_data = [[0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [0]]\n",
    "x_data = np.array(x_data, dtype=np.float32)\n",
    "y_data = np.array(y_data, dtype=np.float32)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name='x_placeholder')\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name='y_placeholder')\n",
    "\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2, 10], -1.0, 1.0), name='weight1')\n",
    "b1 = tf.Variable(tf.zeros([10]), name='bias1')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([10,1], -1.0, 1.0), name='weight1')\n",
    "b2 = tf.Variable(tf.zeros([1]), name='bias2')\n",
    "\n",
    "\n",
    "# Hypothesis using sigmoid: tf.div(1., 1. + tf.exp(tf.matmul(X, W)))\n",
    "L1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "hypothesis = tf.sigmoid(tf.matmul(L1, W2)+b2)\n",
    "\n",
    "# cost/loss function\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy computation\n",
    "# True if hypothesis>0.5 else False\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.75041\n",
      "10000 0.340499\n",
      "20000 0.114214\n",
      "30000 0.0510432\n",
      "40000 0.0297953\n",
      "50000 0.0201914\n",
      "60000 0.014952\n",
      "70000 0.0117267\n",
      "80000 0.00957035\n",
      "90000 0.00804034\n",
      "100000 0.00690516\n",
      "\n",
      "Hypothesis:\n",
      "  [[ 0.00500601]\n",
      " [ 0.9942497 ]\n",
      " [ 0.99207753]\n",
      " [ 0.00884184]] \n",
      "Correct:\n",
      "  [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      "Accuracy:\n",
      "  1.0\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(100001):\n",
    "        sess.run(train, feed_dict={X: x_data, Y: y_data})\n",
    "        if step % 10000 == 0:\n",
    "            print(step, sess.run(cost, feed_dict={\n",
    "                  X: x_data, Y: y_data}))\n",
    "\n",
    "\n",
    "    # Accuracy report\n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy],\n",
    "                       feed_dict={X: x_data, Y: y_data})\n",
    "    print(\"\\nHypothesis:\\n \", h, \"\\nCorrect:\\n \", c, \"\\nAccuracy:\\n \", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 네트워크 구조를 변경하는 것으로 많은 정밀도가 높아짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 행렬곱에서 앞에 행렬은 row를 지배하고\n",
    "- 행렬곱의 두번째 행렬은 comuln을 지배한다.\n",
    "- 두번째 행렬의 column수에 따라서 결과 행렬의 column수가 결정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/26/network1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미스테리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- weight의 column을 늘리면 정밀도가 높아진다.\n",
    "- layer를 높여도 정밀도가 높아진다.\n",
    "- 신기한 일임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-12 05:10:14.468121\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
